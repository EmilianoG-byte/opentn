{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Lindbladian equations to Krauss operators\n",
    "sources: \n",
    "- https://arxiv.org/abs/1412.5746\n",
    "- https://github.com/rigetti/forest-benchmarking/blob/4c2c3bf94af4926b61e9072ca71b914972de338c/forest/benchmarking/operator_tools/superoperator_transformations.py#L1\n",
    "- https://forest-benchmarking.readthedocs.io/en/latest/superoperator_representations.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lindbladian\n",
    "### $\\frac{d{\\rho}}{dt} = -i[{H},{\\rho}] + \\sum_{j=1}^N \\left( {L}_j {\\rho} {L}_j^\\dagger - \\frac{1}{2} {L}_j^\\dagger {L}_j {\\rho} - \\frac{1}{2} {\\rho} {L}_j^\\dagger {L}_j \\right)$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\frac{d{\\rho}}{dt}$ is the time derivative of the density operator ${\\rho}$\n",
    "- ${H}$ is the Hamiltonian operator of the system\n",
    "- ${L}_j$ are the Lindblad operators\n",
    "- $N$ is the number of Lindblad operators\n",
    "- $\\dagger$ denotes the Hermitian conjugate of an operator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Superoperator (Liouville)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mathcal{L} =  -i\\, H \\otimes I + i  \\otimes {H}^T + \\sum_{j} \\left( L_{j} \\otimes L_j^* - \\frac{1}{2} (L^\\dagger_j L_j)\\otimes I  - \\frac{1}{2}\\; I \\otimes (L^T_j L_j^*) \\right)$\n",
    "\n",
    "Which acts on the density matrix as:\n",
    "\n",
    "### $|\\rho(t)\\rangle \\rangle = e^{\\tau \\mathcal L } |\\rho\\rangle\\rangle$\n",
    "### $\\hat{\\mathcal{E}} = |  e^{\\tau \\mathcal L } \\rangle\\rangle$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kraus Channel\n",
    "\n",
    "### $\\mathcal{E}(\\rho(0)) = \\sum_k A_k \\rho(0) A^\\dagger_k = \\rho(t)$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choi-Jamiolkowski Isomorphism\n",
    "\n",
    "\\begin{split}\\begin{align*}\n",
    "\\mathcal C &= I\\otimes \\mathcal E (|\\phi^\\dagger \\rangle \\langle \\phi^\\dagger|) \\\\\\\\\n",
    "&=\\sum_i (A_i \\otimes I) |\\phi^\\dagger \\rangle \\langle \\phi^\\dagger  | ( A_i^\\dagger \\otimes I)\\\\\\\\\n",
    "& = \\frac{1}{d} \\sum_i {\\rm vec}(A_i)  {\\rm vec} (A_i) ^\\dagger \\\\\\\\\n",
    "& = \\frac{1}{d} \\sum_i |A_i\\rangle \\rangle \\langle\\langle A_i |.\n",
    "\\end{align*}\\end{split}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder:\n",
    "Order of legs: (output), (input) = (rows), (columns) (from up to down in a diagram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: \n",
    "get the hamiltonian and jump operators as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "# reload local packages automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from opentn.states.qubits import get_ladder_operator, I\n",
    "import numpy as np\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        +0.j,  0.        +0.j,  0.        +0.j,\n",
       "         0.69314718+0.j],\n",
       "       [ 0.        +0.j, -0.34657359+0.j,  0.        +0.j,\n",
       "         0.        +0.j],\n",
       "       [ 0.        +0.j,  0.        +0.j, -0.34657359+0.j,\n",
       "         0.        +0.j],\n",
       "       [ 0.        +0.j,  0.        +0.j,  0.        +0.j,\n",
       "        -0.69314718+0.j]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Hamilontian\n",
    "H = []\n",
    "\n",
    "# NOTE: the gamma used in ADC is different than the one from the lindbladian\n",
    "# Relation: gamma_adc = 1 - exp(-gamma_lind*t) <-> gamma_lind = -ln(1-gamma_adc)/t\n",
    "gamma_adc = 0.5\n",
    "tao = 1\n",
    "gamma_lind = -np.log(1-gamma_adc)/tao\n",
    "\n",
    "\n",
    "d = 2\n",
    "L1 = np.sqrt(gamma_lind)*get_ladder_operator() # sigma-\n",
    "# L2 = np.sqrt(gamma)*get_ladder_operator(adjoint=True) #sigma+\n",
    "Li = [L1]\n",
    "# Now here I need to create a structure that converts the thins to superoperator (maybe first save them as lindbladian)\n",
    "# TODO: generalize so that we don't have only the same level. Here d=2 everywhere\n",
    "super = np.zeros(shape=(d ** 2, d ** 2),dtype=complex)\n",
    "# if H:\n",
    "#     super = np.kron()\n",
    "for L in Li:\n",
    "    super += np.kron(L, L.conj()) - 0.5*np.kron(L.T.conj()@L, I) - 0.5*np.kron(I, L.T@L.conj())\n",
    "super"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        +0.j, 0.83255461+0.j, 0.        +0.j, 0.        +0.j])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opentn.transformations import vectorize\n",
    "test = vectorize(L1)\n",
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "get exponetial and convert to choi matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        +0.j 0.        +0.j 0.        +0.j 0.5       +0.j]\n",
      " [0.        +0.j 0.70710678+0.j 0.        +0.j 0.        +0.j]\n",
      " [0.        +0.j 0.        +0.j 0.70710678+0.j 0.        +0.j]\n",
      " [0.        +0.j 0.        +0.j 0.        +0.j 0.5       +0.j]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        +0.j, 0.        +0.j, 0.        +0.j, 0.70710678+0.j],\n",
       "       [0.        +0.j, 0.5       +0.j, 0.        +0.j, 0.        +0.j],\n",
       "       [0.        +0.j, 0.        +0.j, 0.        +0.j, 0.        +0.j],\n",
       "       [0.70710678+0.j, 0.        +0.j, 0.        +0.j, 0.5       +0.j]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_exp = expm(super*tao)\n",
    "print(super_exp)\n",
    "# we reshape the thing into tensor of 4 legs\n",
    "choi = np.reshape(super_exp, [d] * 4)\n",
    "choi = choi.swapaxes(1, 2).reshape([d ** 2, d ** 2]) #see graphical proof\n",
    "choi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "get krauss operators using the cholesky decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cholesky: Error\n",
    "`LinAlgError: Matrix is not positive definite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_matrix = np.linalg.cholesky(choi)\n",
    "# A_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigendecomposition: Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        +0.j, -0.70710678+0.j],\n",
       "        [ 0.        +0.j,  0.        +0.j]]),\n",
       " array([[-1.        +0.j,  0.        +0.j],\n",
       "        [ 0.        +0.j, -0.70710678+0.j]])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# krauss operators unvectorized from eigenvector with eigenvalue scaled\n",
    "from opentn.transformations import unvectorize\n",
    "# source: https://stackoverflow.com/questions/5086789/python-is-there-an-inverse-for-ndarray-flattenf\n",
    "\n",
    "# try the eigenvector way\n",
    "eigvals, eigvecs = np.linalg.eigh(choi)\n",
    "\n",
    "tol = 1e-9\n",
    "krauss_list = [np.sqrt(eigval) * unvectorize(np.array(v)) for eigval, v in\n",
    "            zip(eigvals, eigvecs.T) if abs(eigval) > tol]\n",
    "krauss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4],[5,6]])\n",
    "a.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full workflow incorporated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        +0.j, -0.70710678+0.j],\n",
       "        [ 0.        +0.j,  0.        +0.j]]),\n",
       " array([[-1.        +0.j,  0.        +0.j],\n",
       "        [ 0.        +0.j, -0.70710678+0.j]])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opentn.transformations import lindbladian2kraus\n",
    "lindbladian2kraus(Li=[L1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
